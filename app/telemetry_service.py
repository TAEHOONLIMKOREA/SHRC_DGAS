import asyncio
import httpx
import json
from datetime import datetime, timedelta, timezone, date
from typing import Any, Dict, List
from datetime import datetime
from dateutil import parser
from sqlalchemy import text
from .database import async_session
from .config import settings
import orjson
import logging
from collections import defaultdict
from app.database import engine
import asyncpg
import time

logger = logging.getLogger(__name__) 

API_BASE = "https://api.m1ucs.com"

HEADERS = {
    "X-Api-Key": settings.time_EXTERNAL_API_KEY,
    "User-Agent": "Mozilla/5.0 (compatible; SHRC/1.0; +httpx)"
}


client_list = httpx.AsyncClient(
    headers=HEADERS,
    timeout=60.0,
    follow_redirects=False
)

client_detail = httpx.AsyncClient(
    headers=HEADERS,
    timeout=120.0,
    follow_redirects=False,
    verify=False
)



async def get_asyncpg_connection():
    """
    SQLAlchemy ì—”ì§„ì—ì„œ asyncpg ì›ë³¸ connectionì„ ì¶”ì¶œ
    """
    async with engine.begin() as conn:
        raw = await conn.get_raw_connection()
        return raw.driver_connection


# ---------------------------------------------------------
# msgId â†’ í…Œì´ë¸” ë§¤í•‘
# ---------------------------------------------------------
MSG_TABLE_MAP = {
    24: "gps_raw_int_24",
    141: "altitude_141",
    147: "battery_status_147",
    1101: "unknown_1101",
    # í•„ìš”í•œ msgId ì—¬ê¸°ì— ê³„ì† ì¶”ê°€
}

# ---------------------------------------------------------
# ë‚ ì§œ ì²˜ë¦¬ í•¨ìˆ˜
# ---------------------------------------------------------
def _parse_ts(ts: str) -> datetime:
    return datetime.strptime(ts, "%Y%m%d%H%M%S")


def _parse_ts_to_date(ts: str) -> date:
    return _parse_ts(ts).date()


def _iter_dates(start: date, end: date):
    cur = start
    while cur <= end:
        yield cur
        cur += timedelta(days=1)


# ---------------------------------------------------------
# JSON payload â†’ DB ì»¬ëŸ¼ flatten
# ---------------------------------------------------------
def flatten_payload(payload: Dict[str, Any]) -> Dict[str, Any]:
    """
    JSON payloadì˜ í‚¤ ë³€í™˜:
      - "voltages[0]" â†’ voltages_0
    """
    row = {}

    for key, value in payload.items():
        if "[" in key and "]" in key:
            base = key.split("[")[0]
            idx = key.split("[")[1].replace("]", "")
            new_key = f"{base}_{idx}"
            row[new_key] = value
        else:
            row[key] = value

    return row


# ---------------------------------------------------------
# ë©”ì‹œì§€ ëª©ë¡ ì¡°íšŒ
# ---------------------------------------------------------
async def fetch_message_list(robot_id: str, from_ts: str, to_ts: str):
    url = f"{API_BASE}/ext/robots/{robot_id}/telemetries"
    params = {"from": from_ts, "to": to_ts}

    res = await client_list.get(url, params=params)

    if res.status_code == 302:
        raise ValueError("ğŸš« 302 Redirect â†’ ì„œë²„ê°€ ìš”ì²­ì„ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤.")

    res.raise_for_status()
    data = orjson.loads(res.content)
    return data if isinstance(data, list) else [data]


# ---------------------------------------------------------
# ë©”ì‹œì§€ ìƒì„¸ ì¡°íšŒ
# ---------------------------------------------------------
async def fetch_message_detail(robot_id: str, msg_id: int, from_ts: str, to_ts: str):
    url = f"{API_BASE}/ext/robots/{robot_id}/telemetries/{msg_id}"
    params = {"from": from_ts, "to": to_ts}

    res = await client_detail.get(url, params=params)

    if res.status_code == 302:
        raise ValueError("ğŸš« ìƒì„¸ ì¡°íšŒì—ì„œ 302 Redirect ë°œìƒ")

    res.raise_for_status()
    return orjson.loads(res.content)


UUID_TO_NUM = {
    "01fb056f-a3fb-4c38-9f97-ff11b9dea241": 1,
    "163c4473-d37b-4bec-a293-208a69bd2b0d": 2,
    "f6024fc0-e542-4858-9ff4-f7365ef914de": 3,
    "37e05a23-0c44-4384-b48b-031ce0e33e38": 4,
    "dce87884-1065-41f9-b50c-8f6656a8313e": 5,
}
# ---------------------------------------------------------
# Timescale Hypertable ì €ì¥
# ---------------------------------------------------------
async def save_message_to_table(table: str, robot_id: str, payload: Dict[str, Any]):
    """
    shrc.{table} ì— insert
    - payload['time'] ëŠ” ISO8601 ë¬¸ìì—´ (Z í¬í•¨)
    - robot_id ëŠ” FK
    """

    async with async_session() as session:

        cols = ["time", "robot_id"] + [
            key for key in payload.keys() if key != "time"
        ]

        raw_time = payload["time"]

        dt = parser.isoparse(raw_time)


        mapped_robot_id = UUID_TO_NUM.get(robot_id)
        if mapped_robot_id is None:
            raise ValueError(f"Unknown robot_id: {robot_id}")
        
        values = {
            "time": dt,
            "robot_id": mapped_robot_id
        }

        for key, value in payload.items():
            if key != "time":
                values[key] = value

        columns_sql = ", ".join(cols)
        placeholders = ", ".join([f":{c}" for c in cols])

        sql = f"""
        INSERT INTO shrc.{table} ({columns_sql})
        VALUES ({placeholders});
        """
        print(sql)
        await session.execute(text(sql), values)
        await session.commit()

async def save_batch_copy_preprocessed(table: str, rows: list[dict], robot_id: str):

    if not rows:
        return

    batch_columns = None
    batch_values = []   # tuple í˜•íƒœë¡œ ì ìš©í•´ì•¼ binary COPY ë¨

    # ------------------------
    # 1) ê¸°ì¡´ ì „ì²˜ë¦¬ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
    # ------------------------
    for payload in rows:
        cols = ["time", "robot_id"] + [key.lower() for key in payload.keys() if key != "time"]

        if batch_columns is None:
            batch_columns = cols

        dt = parser.isoparse(payload["time"])

        mapped_robot_id = UUID_TO_NUM.get(robot_id)
        if mapped_robot_id is None:
            raise ValueError(f"Unknown robot_id: {robot_id}")

        row_values = [dt, mapped_robot_id]

        for key, value in payload.items():
            if key != "time":
                row_values.append(value)

        batch_values.append(tuple(row_values))  # <-- tuple ì´ì–´ì•¼ í•¨

    # ------------------------
    # 2) SQLAlchemy raw â†’ asyncpg connection
    # ------------------------
    async with engine.begin() as conn:
        raw = await conn.get_raw_connection()
        asyncpg_conn = raw.driver_connection

        await asyncpg_conn.copy_records_to_table(
        table_name=table,               # "gps_raw_int_24"
        schema_name="shrc",             # â† ìŠ¤í‚¤ë§ˆë¥¼ ì—¬ê¸°ì— ë¶„ë¦¬í•´ì„œ ì ì–´ì•¼ í•¨
        records=batch_values,
        columns=batch_columns)


# ---------------------------------------------------------
# ì „ì²´ ë°ì´í„° sync (ì¼ì ë‹¨ìœ„)
# ---------------------------------------------------------
async def sync_telemetry_range(robot_id: str, from_ts: str, to_ts: str) -> int:

    start_date = _parse_ts_to_date(from_ts)
    end_date   = _parse_ts_to_date(to_ts)

    total = 0

    for day in _iter_dates(start_date, end_date):
        day_from = day.strftime("%Y%m%d000000")
        day_to   = day.strftime("%Y%m%d235959")

        print(f"\n===== {day} ëª©ë¡ ì¡°íšŒ =====")

        msg_list = await fetch_message_list(robot_id, day_from, day_to)

        for item in msg_list:
            msg_id = item.get("msgId")
            msg_name = item.get("msgName")

            if msg_id not in MSG_TABLE_MAP:
                print(f"âš  msgId={msg_id} ({msg_name}) â†’ ì €ì¥ í…Œì´ë¸” ì—†ìŒ")
                continue

            print(f" â†’ ìƒì„¸ ì¡°íšŒ msgId={msg_id} ({msg_name})")

            detail = await fetch_message_detail(robot_id, msg_id, day_from, day_to)

            # ğŸ”¥ ë¦¬ìŠ¤íŠ¸ë©´ ì „ì²´ ì €ì¥, ë‹¨ì¼ ê°ì²´ë©´ í•˜ë‚˜ë§Œ ì €ì¥
            detail_list = detail if isinstance(detail, list) else [detail]

            table = MSG_TABLE_MAP[msg_id]

            for payload in detail_list:
                print(payload)

                flat = flatten_payload(payload)
                print(flat)

                await save_message_to_table(table, robot_id, flat)
                total += 1

    return total

# ---------------------------------------------------------
# ìµœê·¼ 10ì´ˆ ë“± ì§§ì€ ë²”ìœ„ sync
# ---------------------------------------------------------
# async def sync_recent_telemetry(robot_id: str, from_ts: str, to_ts: str) -> int:

#     print(f"\n[RECENT] {robot_id} â†’ {from_ts} ~ {to_ts}")

#     total = 0

#     msg_list = await fetch_message_list(robot_id, from_ts, to_ts)

#     for item in msg_list:
#         msg_id = item.get("msgId")

#         if msg_id not in MSG_TABLE_MAP:
#             continue
#         # time check
#         detail = await fetch_message_detail(robot_id, msg_id, from_ts, to_ts)

#         detail_list = detail if isinstance(detail, list) else [detail]

#         table = MSG_TABLE_MAP[msg_id]

#         # time check
#         for payload in detail_list:
#             print(payload)

#             flat = flatten_payload(payload)
#             print(flat)

#             await save_message_to_table(table, robot_id, flat)
#             total += 1

#     return total


async def sync_recent_telemetry(robot_id: str, from_ts: str, to_ts: str) -> int:
    start_time = time.time()
    logger.info(f"[SYNC START] robot_id={robot_id}, range={from_ts} â†’ {to_ts}")

    total = 0
    msg_list = await fetch_message_list(robot_id, from_ts, to_ts)
    logger.info(f"[MSG LIST] robot_id={robot_id}, count={len(msg_list)} received")

    tasks = []
    msg_ids = []

    for item in msg_list:
        msg_id = item.get("msgId")
        if msg_id not in MSG_TABLE_MAP:
            logger.debug(f"[SKIP] msgId={msg_id} (not in MSG_TABLE_MAP)")
            continue

        tasks.append(fetch_message_detail(robot_id, msg_id, from_ts, to_ts))
        msg_ids.append(msg_id)

    if not tasks:
        logger.warning(f"[NO VALID DATA] robot_id={robot_id} - No messages to process")
        return 0

    logger.info(f"[DETAIL REQUEST] total={len(tasks)} messages, starting async fetch")

    # ë³‘ë ¬ ì‹¤í–‰
    try:
        details = await asyncio.gather(*tasks)
    except Exception as e:
        logger.error(f"[DETAIL FETCH ERROR] robot_id={robot_id}, error={e}", exc_info=True)
        raise

    # -------------------------------------------------------
    # 2) í…Œì´ë¸”ë³„ë¡œ payloadë¥¼ ë²„í¼ë§
    # -------------------------------------------------------
    # buffer[table_name] = [payload, payload, ...]
    buffer = defaultdict(list)

    for msg_id, detail in zip(msg_ids, details):
        table = MSG_TABLE_MAP[msg_id]

        detail_list = detail if isinstance(detail, list) else [detail]

        logger.debug(f"[PROCESS] msgId={msg_id}, rows={len(detail_list)}")

        for payload in detail_list:
            flat = flatten_payload(payload)  # ê¸°ì¡´ flatten ìœ ì§€
            buffer[table].append(flat)
            total += 1

    # -------------------------------------------------------
    # 3) COPY ê¸°ë°˜ ëŒ€ëŸ‰ insert ìˆ˜í–‰
    # -------------------------------------------------------
    for table, rows in buffer.items():
        logger.info(f"[COPY INSERT] table={table}, rows={len(rows)}")
        try:
            await save_batch_copy_preprocessed(table, rows, robot_id)
            logger.info(f"[COPY SUCCESS] table={table}, rows={len(rows)}")
        except Exception as e:
            logger.error(
                f"[COPY ERROR] table={table}, rows={len(rows)}, error={e}",
                exc_info=True
            )
            raise
        
    elapsed = time.time() - start_time
    logger.info(f"[SYNC DONE] robot_id={robot_id}, total_rows={total}, elapsed={elapsed:.2f}s")       

    return total
